{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187758b1",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832287d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>riasec</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Casey</td>\n",
       "      <td>paul.casey.1@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Bachelor of Statistics</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Sandoval</td>\n",
       "      <td>danielle.sandoval.2@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>Bachelor of Supply Chain Management</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>tina.andrews.3@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>Bachelor of Corporate Communications</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tara</td>\n",
       "      <td>Clark</td>\n",
       "      <td>tara.clark.4@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>Bachelor of Human Resouce Management</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Campos</td>\n",
       "      <td>anthony.campos.5@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>Bachelor of Development Studies</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name last_name                                  email  gender  \\\n",
       "0   1       Paul     Casey         paul.casey.1@gslingacademy.com    male   \n",
       "1   2   Danielle  Sandoval  danielle.sandoval.2@gslingacademy.com  female   \n",
       "2   3       Tina   Andrews       tina.andrews.3@gslingacademy.com  female   \n",
       "3   4       Tara     Clark         tara.clark.4@gslingacademy.com  female   \n",
       "4   5    Anthony    Campos     anthony.campos.5@gslingacademy.com    male   \n",
       "\n",
       "   extracurricular_activities  riasec                     career_aspiration  \\\n",
       "0                       False      27                Bachelor of Statistics   \n",
       "1                       False      40   Bachelor of Supply Chain Management   \n",
       "2                        True      30  Bachelor of Corporate Communications   \n",
       "3                       False      40  Bachelor of Human Resouce Management   \n",
       "4                       False      25       Bachelor of Development Studies   \n",
       "\n",
       "   math_score  history_score  physics_score  chemistry_score  biology_score  \\\n",
       "0          73             81             93               97             63   \n",
       "1          90             86             96              100             90   \n",
       "2          81             97             95               96             65   \n",
       "3          71             74             88               80             89   \n",
       "4          84             77             65               65             80   \n",
       "\n",
       "   english_score  geography_score  \n",
       "0             80               87  \n",
       "1             88               90  \n",
       "2             77               94  \n",
       "3             63               86  \n",
       "4             74               76  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"student-scores.csv\")\n",
    "df = df1.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f3efa",
   "metadata": {},
   "source": [
    "# drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5e304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.drop(columns=['id','first_name','last_name','email'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad3f4c",
   "metadata": {},
   "source": [
    "# create new features from all score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b35efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>riasec</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Bachelor of Statistics</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>Bachelor of Supply Chain Management</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>Bachelor of Corporate Communications</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>Bachelor of Human Resouce Management</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>Bachelor of Development Studies</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  extracurricular_activities  riasec  \\\n",
       "0    male                       False      27   \n",
       "1  female                       False      40   \n",
       "2  female                        True      30   \n",
       "3  female                       False      40   \n",
       "4    male                       False      25   \n",
       "\n",
       "                      career_aspiration  math_score  history_score  \\\n",
       "0                Bachelor of Statistics          73             81   \n",
       "1   Bachelor of Supply Chain Management          90             86   \n",
       "2  Bachelor of Corporate Communications          81             97   \n",
       "3  Bachelor of Human Resouce Management          71             74   \n",
       "4       Bachelor of Development Studies          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"total_score\"] = df[\"math_score\"] + df[\"history_score\"] + df[\"physics_score\"] + df[\"chemistry_score\"] + df[\"biology_score\"] + df[\"english_score\"] + df[\"geography_score\"]\n",
    "df[\"average_score\"] = df[\"total_score\"] / 7\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54218d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>riasec</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Bachelor of Statistics</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>Bachelor of Supply Chain Management</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>Bachelor of Corporate Communications</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>Bachelor of Human Resouce Management</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>Bachelor of Development Studies</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  extracurricular_activities  riasec  \\\n",
       "0    male                       False      27   \n",
       "1  female                       False      40   \n",
       "2  female                        True      30   \n",
       "3  female                       False      40   \n",
       "4    male                       False      25   \n",
       "\n",
       "                      career_aspiration  math_score  history_score  \\\n",
       "0                Bachelor of Statistics          73             81   \n",
       "1   Bachelor of Supply Chain Management          90             86   \n",
       "2  Bachelor of Corporate Communications          81             97   \n",
       "3  Bachelor of Human Resouce Management          71             74   \n",
       "4       Bachelor of Development Studies          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd850b",
   "metadata": {},
   "source": [
    "# Encoding Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d54762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Create a LabelEncoder object\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# # Encode categorical columns using label encoder\n",
    "# df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "# df['part_time_job'] = label_encoder.fit_transform(df['part_time_job'])\n",
    "# df['riasec'] = label_encoder.fit_transform(df['riasec'])\n",
    "# df['career_aspiration'] = label_encoder.fit_transform(df['career_aspiration'])\n",
    "# Define mapping dictionaries for categorical features\n",
    "gender_map = {'male': 0, 'female': 1}\n",
    "extracurricular_activities_map = {False: 0, True: 1}\n",
    "career_aspiration_map = {\n",
    "    \"Bachelor of Statistics\": 0,\n",
    "    \"Bachelor of Supply Chain Management\": 1,\n",
    "    \"Bachelor of Corporate Communications\": 2,\n",
    "    \"Bachelor of Human Resouce Management\": 3,\n",
    "    \"Bachelor of Development Studies\": 4,\n",
    "    \"Bachelor of Procurement and Contract Management\": 5,\n",
    "    \"Bachelor of Project Management\": 6,\n",
    "    \"Bachelor of Business Administration\": 7,\n",
    "    \"Bachelor of Journalism\": 8,\n",
    "    \"Bachelor of Business and Office Management\": 9,\n",
    "    \"Bachelor of Economics and Statistics\": 10,\n",
    "    \"Bachelor of Mass Communication\": 11,\n",
    "    \"Bachelor of Commerce\": 12,\n",
    "    \"Bachelor of Procurement and Logistics\": 13,\n",
    "    \"Bachelor of Finance\": 14,\n",
    "    \"Bachelor of Business Information Technology\": 15,\n",
    "    \"Bachelor of Technology and Entrepreneurship Management\": 16,\n",
    "}\n",
    "# Apply mapping to the DataFrame\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map(extracurricular_activities_map)\n",
    "df['career_aspiration'] = df['career_aspiration'].map(career_aspiration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc961a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>riasec</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  extracurricular_activities  riasec  career_aspiration  math_score  \\\n",
       "0       0                           0      27                  0          73   \n",
       "1       1                           0      40                  1          90   \n",
       "2       1                           1      30                  2          81   \n",
       "3       1                           0      40                  3          71   \n",
       "4       0                           0      25                  4          84   \n",
       "\n",
       "   history_score  physics_score  chemistry_score  biology_score  \\\n",
       "0             81             93               97             63   \n",
       "1             86             96              100             90   \n",
       "2             97             95               96             65   \n",
       "3             74             88               80             89   \n",
       "4             77             65               65             80   \n",
       "\n",
       "   english_score  geography_score  total_score  average_score  \n",
       "0             80               87          574      82.000000  \n",
       "1             88               90          640      91.428571  \n",
       "2             77               94          605      86.428571  \n",
       "3             63               86          551      78.714286  \n",
       "4             74               76          521      74.428571  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8c23b",
   "metadata": {},
   "source": [
    "# Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7fd61cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 15, 13, 16,  8, 14],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473b122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "career_aspiration\n",
       "5     315\n",
       "7     309\n",
       "4     223\n",
       "10    169\n",
       "0     138\n",
       "12    126\n",
       "1     119\n",
       "14     83\n",
       "8      73\n",
       "13     68\n",
       "3      67\n",
       "16     63\n",
       "2      61\n",
       "6      59\n",
       "15     56\n",
       "9      39\n",
       "11     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e9f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('career_aspiration', axis=1)\n",
    "y = df['career_aspiration']\n",
    "\n",
    "# Apply SMOTE to the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93694ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in y: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaNs in y:\", y.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14149af8",
   "metadata": {},
   "source": [
    "# Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2dd8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12984069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a93ee",
   "metadata": {},
   "source": [
    "# Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e08701dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37bcd1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b5a5f",
   "metadata": {},
   "source": [
    "# Models Training (Multiple Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49d8f73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.34827264239028943\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.25      0.27        68\n",
      "           1       0.40      0.71      0.51        72\n",
      "           2       0.22      0.12      0.16        57\n",
      "           3       0.24      0.16      0.19        58\n",
      "           4       0.33      0.09      0.14        66\n",
      "           5       0.29      0.25      0.27        76\n",
      "           6       0.40      0.62      0.49        71\n",
      "           7       0.47      0.46      0.46        61\n",
      "           8       0.24      0.33      0.28        49\n",
      "           9       0.33      0.37      0.35        63\n",
      "          10       0.22      0.11      0.15        64\n",
      "          11       0.35      0.66      0.46        50\n",
      "          12       0.41      0.41      0.41        69\n",
      "          13       0.35      0.56      0.43        55\n",
      "          14       0.36      0.16      0.22        62\n",
      "          15       0.12      0.05      0.07        65\n",
      "          16       0.47      0.63      0.54        65\n",
      "\n",
      "    accuracy                           0.35      1071\n",
      "   macro avg       0.32      0.35      0.32      1071\n",
      "weighted avg       0.32      0.35      0.32      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17  6  2  3  0  4  5  1  4  2  2 11  3  3  0  3  2]\n",
      " [ 2 51  0  0  0  5  1  0  0  8  0  0  0  4  0  0  1]\n",
      " [ 3  2  7  4  0  1  2  4 10  3  0  7  4  7  0  2  1]\n",
      " [ 2  7  8  9  3  2  8  2  2  3  1  0  1  1  5  0  4]\n",
      " [ 7  7  1  3  6  5  5  5  2  2  2  1  3  4  1  7  5]\n",
      " [ 4  8  0  0  1 19  1  1  6  2 10  1  6 11  2  0  4]\n",
      " [ 2  0  0  4  0  2 44  3  0  1  2 10  1  0  0  0  2]\n",
      " [ 0  0  0  2  3  7  2 28  0  0  1  4  6  0  2  0  6]\n",
      " [ 3  3  1  2  1  4  0  1 16  3  3  0  7  2  1  2  0]\n",
      " [ 0 20  1  0  0  0  0  0  0 23  1 11  0  1  3  0  3]\n",
      " [ 7  4  0  3  0  8 13  1  3  1  7  3  4  4  0  2  4]\n",
      " [ 1  2  1  0  0  0  6  0  0  2  1 33  0  0  0  2  2]\n",
      " [ 0  7  1  0  1  5  3  2 10  0  1  1 28  6  1  2  1]\n",
      " [ 3  4  0  0  1  0  0  0  5  2  0  2  0 31  1  0  6]\n",
      " [ 2  1  3  4  1  2  8 10  6  0  1  3  6  1 10  3  1]\n",
      " [ 4  4  6  3  1  1  8  1  3 12  0  5  0  8  2  3  4]\n",
      " [ 0  3  1  0  0  1  3  1  0  6  0  3  0  6  0  0 41]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.5508870214752568\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.44      0.43        68\n",
      "           1       0.54      0.85      0.66        72\n",
      "           2       0.48      0.44      0.46        57\n",
      "           3       0.61      0.60      0.61        58\n",
      "           4       0.57      0.12      0.20        66\n",
      "           5       0.38      0.33      0.35        76\n",
      "           6       0.58      0.89      0.70        71\n",
      "           7       0.90      0.62      0.74        61\n",
      "           8       0.42      0.45      0.44        49\n",
      "           9       0.53      0.78      0.63        63\n",
      "          10       0.36      0.28      0.32        64\n",
      "          11       0.58      0.86      0.69        50\n",
      "          12       0.80      0.41      0.54        69\n",
      "          13       0.47      0.65      0.55        55\n",
      "          14       0.60      0.52      0.56        62\n",
      "          15       0.59      0.45      0.51        65\n",
      "          16       0.71      0.74      0.72        65\n",
      "\n",
      "    accuracy                           0.55      1071\n",
      "   macro avg       0.56      0.55      0.54      1071\n",
      "weighted avg       0.56      0.55      0.53      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30  5  3  1  1  2  5  0  0  3  4  8  0  4  0  1  1]\n",
      " [ 1 61  0  0  0  1  1  0  0  6  0  0  0  2  0  0  0]\n",
      " [ 4  1 25  3  0  1  3  0  8  3  1  6  0  1  0  1  0]\n",
      " [ 1  7  3 35  2  2  1  0  2  1  1  0  0  1  1  1  0]\n",
      " [ 5  6  0  2  8  5  7  0  1  2  5  3  3  3  6  7  3]\n",
      " [ 2  9  5  2  0 25  2  1  5  3  8  0  1  9  1  1  2]\n",
      " [ 2  0  0  0  0  1 63  0  0  0  3  2  0  0  0  0  0]\n",
      " [ 1  0  1  4  0  6  1 38  0  0  1  1  1  2  2  1  2]\n",
      " [ 6  2  3  0  1  4  0  0 22  1  6  0  0  4  0  0  0]\n",
      " [ 0 10  0  0  0  0  0  0  0 49  0  2  0  0  1  0  1]\n",
      " [ 9  0  0  1  1  3 10  0  3  4 18  3  1  3  3  3  2]\n",
      " [ 0  0  1  0  0  0  4  0  0  0  0 43  0  0  0  0  2]\n",
      " [ 2  4  5  1  1  5  1  0  5  5  3  1 28  4  4  0  0]\n",
      " [ 1  3  0  1  0  0  0  0  3  4  0  0  0 36  1  2  4]\n",
      " [ 1  1  2  6  0  8  5  2  2  0  0  1  1  0 32  1  0]\n",
      " [ 5  4  4  1  0  0  3  0  0  6  0  3  0  5  2 29  3]\n",
      " [ 0  0  0  0  0  2  2  1  1  6  0  1  0  2  0  2 48]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.7945845004668534\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72        68\n",
      "           1       0.83      0.97      0.90        72\n",
      "           2       0.87      0.82      0.85        57\n",
      "           3       0.81      0.88      0.84        58\n",
      "           4       0.73      0.45      0.56        66\n",
      "           5       0.47      0.24      0.32        76\n",
      "           6       0.82      0.92      0.87        71\n",
      "           7       0.92      0.74      0.82        61\n",
      "           8       0.82      0.94      0.88        49\n",
      "           9       0.81      0.97      0.88        63\n",
      "          10       0.67      0.77      0.72        64\n",
      "          11       0.81      1.00      0.89        50\n",
      "          12       0.93      0.74      0.82        69\n",
      "          13       0.70      1.00      0.82        55\n",
      "          14       0.86      0.82      0.84        62\n",
      "          15       0.90      0.86      0.88        65\n",
      "          16       0.80      0.85      0.82        65\n",
      "\n",
      "    accuracy                           0.79      1071\n",
      "   macro avg       0.79      0.81      0.79      1071\n",
      "weighted avg       0.79      0.79      0.78      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[51  2  0  0  2  0  0  1  1  3  3  1  1  1  0  1  1]\n",
      " [ 0 70  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0]\n",
      " [ 2  0 47  0  0  1  2  0  1  0  1  2  0  0  0  1  0]\n",
      " [ 1  3  0 51  0  0  0  0  0  0  1  0  0  0  0  0  2]\n",
      " [ 5  2  2  1 30  4  3  1  2  3  5  2  0  1  1  2  2]\n",
      " [ 6  5  3  2  3 18  4  0  5  4  8  0  0 11  2  0  5]\n",
      " [ 1  0  1  0  0  1 65  0  0  0  2  0  1  0  0  0  0]\n",
      " [ 1  0  0  3  2  3  1 45  1  0  0  0  0  2  1  1  1]\n",
      " [ 2  0  0  0  0  0  0  0 46  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 61  0  1  0  0  0  0  1]\n",
      " [ 2  1  0  3  1  1  1  0  0  1 49  4  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0  0]\n",
      " [ 1  0  0  0  1  5  1  0  0  0  2  0 51  6  1  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 55  0  0  0]\n",
      " [ 0  0  1  3  1  2  0  2  0  0  0  1  1  0 51  0  0]\n",
      " [ 1  1  0  0  0  0  2  0  0  0  0  1  0  0  2 56  2]\n",
      " [ 0  0  0  0  1  3  0  0  0  2  1  0  0  3  0  0 55]]\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.6414565826330533\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.66      0.62        68\n",
      "           1       0.77      0.89      0.83        72\n",
      "           2       0.62      0.88      0.72        57\n",
      "           3       0.53      0.71      0.60        58\n",
      "           4       0.32      0.15      0.21        66\n",
      "           5       0.32      0.12      0.17        76\n",
      "           6       0.77      0.87      0.82        71\n",
      "           7       0.81      0.28      0.41        61\n",
      "           8       0.50      0.67      0.57        49\n",
      "           9       0.69      0.92      0.79        63\n",
      "          10       0.56      0.48      0.52        64\n",
      "          11       0.70      0.98      0.82        50\n",
      "          12       0.72      0.48      0.57        69\n",
      "          13       0.63      0.87      0.73        55\n",
      "          14       0.68      0.55      0.61        62\n",
      "          15       0.68      0.82      0.74        65\n",
      "          16       0.77      0.77      0.77        65\n",
      "\n",
      "    accuracy                           0.64      1071\n",
      "   macro avg       0.63      0.65      0.62      1071\n",
      "weighted avg       0.63      0.64      0.61      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[45  2  0  2  2  2  0  0  4  0  2  6  0  0  0  2  1]\n",
      " [ 0 64  0  0  0  1  1  0  2  1  1  0  0  1  0  1  0]\n",
      " [ 1  0 50  0  1  0  1  0  1  0  1  1  0  0  0  1  0]\n",
      " [ 2  4  1 41  3  1  0  0  1  1  1  0  0  0  0  0  3]\n",
      " [ 5  3  7  2 10  2  6  1  5  6  3  1  4  2  4  4  1]\n",
      " [ 8  4  6  5  3  9  0  0  8  4  6  2  2  9  3  3  4]\n",
      " [ 0  0  1  4  0  0 62  0  0  0  3  0  1  0  0  0  0]\n",
      " [ 2  1  3  4  7  1  0 17  4  0  4  1  1  5  2  6  3]\n",
      " [ 1  1  4  3  0  1  0  0 33  1  1  0  0  3  1  0  0]\n",
      " [ 0  1  0  1  0  0  0  0  0 58  0  1  0  1  0  1  0]\n",
      " [ 6  0  2  2  1  4  1  0  2  1 31  3  3  1  3  2  2]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0 49  0  0  0  0  0]\n",
      " [ 2  1  4  3  4  4  3  0  3  3  0  1 33  5  2  1  0]\n",
      " [ 1  0  0  1  0  0  0  0  0  0  1  0  0 48  1  2  1]\n",
      " [ 3  0  3  7  0  3  4  1  1  2  0  1  2  1 34  0  0]\n",
      " [ 1  2  0  0  0  0  2  2  0  2  0  3  0  0  0 53  0]\n",
      " [ 0  0  0  3  0  0  1  0  2  5  1  1  0  0  0  2 50]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.6078431372549019\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.49      0.54        68\n",
      "           1       0.73      0.82      0.77        72\n",
      "           2       0.56      0.60      0.58        57\n",
      "           3       0.63      0.69      0.66        58\n",
      "           4       0.30      0.27      0.29        66\n",
      "           5       0.21      0.16      0.18        76\n",
      "           6       0.76      0.75      0.75        71\n",
      "           7       0.63      0.54      0.58        61\n",
      "           8       0.55      0.61      0.58        49\n",
      "           9       0.80      0.84      0.82        63\n",
      "          10       0.48      0.47      0.47        64\n",
      "          11       0.71      0.90      0.80        50\n",
      "          12       0.68      0.57      0.62        69\n",
      "          13       0.67      0.85      0.75        55\n",
      "          14       0.67      0.60      0.63        62\n",
      "          15       0.51      0.60      0.55        65\n",
      "          16       0.74      0.75      0.75        65\n",
      "\n",
      "    accuracy                           0.61      1071\n",
      "   macro avg       0.60      0.62      0.61      1071\n",
      "weighted avg       0.60      0.61      0.60      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[33  1  6  2  2  7  0  0  3  1  1  2  2  0  1  6  1]\n",
      " [ 2 59  0  0  0  1  0  1  0  1  0  0  2  2  0  2  2]\n",
      " [ 1  1 34  2  2  3  2  1  1  1  2  4  0  2  1  0  0]\n",
      " [ 0  3  2 40  2  0  1  1  1  2  2  0  0  1  1  2  0]\n",
      " [ 2  3  2  4 18  7  2  9  1  0  3  3  0  1  1  6  4]\n",
      " [ 4  3  3  4  5 12  4  0  7  5 12  2  2  5  4  1  3]\n",
      " [ 1  1  3  0  5  0 53  0  1  0  2  0  1  1  1  1  1]\n",
      " [ 2  0  1  4  9  1  0 33  3  0  0  0  1  1  1  4  1]\n",
      " [ 0  1  3  2  5  6  1  0 30  0  0  0  0  1  0  0  0]\n",
      " [ 0  2  0  0  0  2  0  0  0 53  2  0  2  0  0  1  1]\n",
      " [ 3  2  0  1  0  7  2  0  3  0 30  6  5  0  1  3  1]\n",
      " [ 1  0  1  0  1  0  0  0  0  1  1 45  0  0  0  0  0]\n",
      " [ 1  1  2  2  0  2  1  2  2  1  3  0 39  4  2  7  0]\n",
      " [ 0  0  1  1  0  0  1  0  0  1  1  0  0 47  2  0  1]\n",
      " [ 1  0  1  0  6  3  1  4  2  0  1  0  2  0 37  2  2]\n",
      " [ 3  3  2  1  4  3  2  0  1  0  2  1  1  2  1 39  0]\n",
      " [ 1  1  0  0  1  4  0  1  0  0  1  0  0  3  2  2 49]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.19794584500466852\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.01      0.03        68\n",
      "           1       0.53      0.28      0.36        72\n",
      "           2       0.00      0.00      0.00        57\n",
      "           3       0.60      0.05      0.10        58\n",
      "           4       0.57      0.06      0.11        66\n",
      "           5       0.50      0.09      0.16        76\n",
      "           6       0.19      0.97      0.31        71\n",
      "           7       0.51      0.36      0.42        61\n",
      "           8       0.12      0.02      0.04        49\n",
      "           9       0.00      0.00      0.00        63\n",
      "          10       0.00      0.00      0.00        64\n",
      "          11       0.70      0.28      0.40        50\n",
      "          12       1.00      0.07      0.14        69\n",
      "          13       0.10      0.98      0.18        55\n",
      "          14       0.58      0.11      0.19        62\n",
      "          15       0.56      0.08      0.14        65\n",
      "          16       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.20      1071\n",
      "   macro avg       0.36      0.20      0.15      1071\n",
      "weighted avg       0.36      0.20      0.15      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1  0  1  0  0  0 21  0  0  0  0  1  0 44  0  0  0]\n",
      " [ 0 20  0  0  0  0 17  0  0  0  0  0  0 35  0  0  0]\n",
      " [ 0  0  0  0  1  0 12  3  3  0  0  1  0 37  0  0  0]\n",
      " [ 0  0  1  3  1  0 23  3  0  0  0  0  0 27  0  0  0]\n",
      " [ 0  2  0  0  4  1 22  2  1  0  0  0  0 29  2  3  0]\n",
      " [ 0  2  0  0  0  7 27  1  1  0  0  0  0 37  0  1  0]\n",
      " [ 0  0  0  0  0  0 69  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  1 21 22  0  0  0  0  0 12  3  0  0]\n",
      " [ 0  0  0  0  0  2  5  3  1  0  0  0  0 38  0  0  0]\n",
      " [ 0  6  0  0  0  0 15  0  0  0  0  0  0 42  0  0  0]\n",
      " [ 0  2  0  0  1  1 31  0  0  0  0  0  0 29  0  0  0]\n",
      " [ 2  1  1  0  0  0 14  0  0  0  0 14  0 18  0  0  0]\n",
      " [ 0  0  0  0  0  1 19  2  1  0  0  0  5 41  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0 54  0  0  0]\n",
      " [ 1  1  0  0  0  1 30  5  0  0  0  1  0 16  7  0  0]\n",
      " [ 3  3  1  0  0  0 19  0  1  0  0  3  0 30  0  5  0]\n",
      " [ 0  0  0  0  0  0 24  0  0  0  0  0  0 41  0  0  0]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.1839402427637722\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.04      0.08        68\n",
      "           1       0.64      0.10      0.17        72\n",
      "           2       0.00      0.00      0.00        57\n",
      "           3       0.23      0.09      0.12        58\n",
      "           4       0.24      0.06      0.10        66\n",
      "           5       0.14      0.05      0.08        76\n",
      "           6       0.00      0.00      0.00        71\n",
      "           7       0.16      0.87      0.27        61\n",
      "           8       0.15      0.24      0.19        49\n",
      "           9       0.17      0.62      0.27        63\n",
      "          10       0.20      0.02      0.03        64\n",
      "          11       0.19      0.42      0.26        50\n",
      "          12       1.00      0.09      0.16        69\n",
      "          13       0.27      0.29      0.28        55\n",
      "          14       0.27      0.13      0.17        62\n",
      "          15       0.00      0.00      0.00        65\n",
      "          16       0.15      0.28      0.20        65\n",
      "\n",
      "    accuracy                           0.18      1071\n",
      "   macro avg       0.25      0.19      0.14      1071\n",
      "weighted avg       0.26      0.18      0.13      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 3  0  0  1  0  2  0 17 11 23  0  8  0  0  1  0  2]\n",
      " [ 0  7  0  5  0  2  0  3  0 21  0  1  0  1  0  0 32]\n",
      " [ 1  0  0  1  4  1  0 16  8 14  0  4  0  3  2  0  3]\n",
      " [ 0  3  0  5  0  0  0 28  5  5  0  5  0  0  1  0  6]\n",
      " [ 1  0  1  0  4  0  0 25  7  9  1  7  0  1  3  0  7]\n",
      " [ 1  0  0  2  0  4  0 14  8 15  1  9  0  9  0  0 13]\n",
      " [ 0  0  0  3  0  4  0 35  5  2  1 11  0  0  5  0  5]\n",
      " [ 0  0  0  1  0  1  0 53  0  0  0  1  0  1  2  0  2]\n",
      " [ 0  0  0  0  3  0  0 13 12  8  1  3  0  6  1  0  2]\n",
      " [ 0  0  0  0  1  1  0  0  0 39  0 14  0  1  0  0  7]\n",
      " [ 0  0  2  1  0  5  0 16  6 15  1 11  0  1  1  0  5]\n",
      " [ 0  0  0  0  0  0  1 22  0  6  0 21  0  0  0  0  0]\n",
      " [ 0  0  4  0  3  4  0 31  3 12  0  4  6  1  0  0  1]\n",
      " [ 0  0  1  1  0  0  0  4  0 33  0  0  0 16  0  0  0]\n",
      " [ 1  0  2  1  1  2  0 34  5  0  0  2  0  2  8  0  4]\n",
      " [ 0  0  2  0  1  1  0 16  8 12  0  6  0  4  5  0 10]\n",
      " [ 0  1  0  1  0  2  0  6  0 16  0  6  0 14  1  0 18]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.6713352007469654\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.57      0.53        68\n",
      "           1       0.79      0.94      0.86        72\n",
      "           2       0.72      0.67      0.69        57\n",
      "           3       0.67      0.74      0.70        58\n",
      "           4       0.46      0.17      0.24        66\n",
      "           5       0.44      0.33      0.38        76\n",
      "           6       0.71      0.89      0.79        71\n",
      "           7       0.98      0.84      0.90        61\n",
      "           8       0.65      0.65      0.65        49\n",
      "           9       0.74      0.92      0.82        63\n",
      "          10       0.38      0.39      0.38        64\n",
      "          11       0.71      0.92      0.80        50\n",
      "          12       0.85      0.57      0.68        69\n",
      "          13       0.59      0.93      0.72        55\n",
      "          14       0.80      0.52      0.63        62\n",
      "          15       0.70      0.74      0.72        65\n",
      "          16       0.74      0.77      0.75        65\n",
      "\n",
      "    accuracy                           0.67      1071\n",
      "   macro avg       0.67      0.68      0.66      1071\n",
      "weighted avg       0.67      0.67      0.66      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[39  4  0  1  2  4  1  0  2  1  5  2  2  1  0  3  1]\n",
      " [ 0 68  0  0  0  0  0  0  0  2  1  0  0  1  0  0  0]\n",
      " [ 1  2 38  1  0  1  3  0  1  1  1  3  0  2  0  2  1]\n",
      " [ 3  2  2 43  2  0  2  0  0  1  2  0  0  0  0  0  1]\n",
      " [ 6  2  3  3 11  5  3  0  1  2  8  2  1  2  6  6  5]\n",
      " [ 5  2  0  2  3 25  4  0  6  3  6  1  1 13  0  2  3]\n",
      " [ 1  0  0  0  0  0 63  0  0  0  5  2  0  0  0  0  0]\n",
      " [ 1  0  0  2  1  2  3 51  0  0  0  0  1  0  0  0  0]\n",
      " [ 2  0  0  2  0  3  0  0 32  0  4  0  1  3  2  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0 58  0  1  0  1  0  0  1]\n",
      " [10  1  2  1  1  5  3  0  2  2 25  5  0  3  0  3  1]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0 46  0  0  0  0  2]\n",
      " [ 1  2  3  2  0  1  1  1  2  4  5  1 39  4  0  2  1]\n",
      " [ 0  0  1  0  0  1  0  0  0  1  0  0  0 51  0  0  1]\n",
      " [ 3  1  2  5  3  5  3  0  2  0  3  1  0  1 32  1  0]\n",
      " [ 3  0  2  1  1  2  3  0  0  1  0  1  1  1  0 48  1]\n",
      " [ 2  0  0  1  0  3  0  0  1  2  1  0  0  3  0  2 50]]\n",
      "==================================================\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.780578898225957\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68        68\n",
      "           1       0.89      0.93      0.91        72\n",
      "           2       0.85      0.88      0.86        57\n",
      "           3       0.84      0.83      0.83        58\n",
      "           4       0.69      0.38      0.49        66\n",
      "           5       0.42      0.33      0.37        76\n",
      "           6       0.86      0.87      0.87        71\n",
      "           7       0.96      0.79      0.86        61\n",
      "           8       0.74      0.86      0.79        49\n",
      "           9       0.91      0.98      0.95        63\n",
      "          10       0.56      0.67      0.61        64\n",
      "          11       0.86      0.98      0.92        50\n",
      "          12       0.80      0.71      0.75        69\n",
      "          13       0.75      1.00      0.86        55\n",
      "          14       0.88      0.81      0.84        62\n",
      "          15       0.81      0.89      0.85        65\n",
      "          16       0.84      0.83      0.84        65\n",
      "\n",
      "    accuracy                           0.78      1071\n",
      "   macro avg       0.78      0.79      0.78      1071\n",
      "weighted avg       0.78      0.78      0.77      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49  0  0  2  1  4  0  0  1  0  4  0  3  1  0  1  2]\n",
      " [ 0 67  0  0  0  1  0  0  0  1  1  0  1  0  0  1  0]\n",
      " [ 1  0 50  0  0  2  2  0  0  0  0  1  0  0  0  1  0]\n",
      " [ 2  2  1 48  2  0  0  1  0  0  0  0  1  0  0  0  1]\n",
      " [ 7  2  2  3 25  4  2  0  2  0  4  2  1  1  4  5  2]\n",
      " [ 7  3  2  0  1 25  1  0  7  2  9  1  2 10  2  0  4]\n",
      " [ 0  0  0  0  0  2 62  0  0  0  6  0  0  0  0  1  0]\n",
      " [ 1  0  0  3  3  2  2 48  0  0  0  0  2  0  0  0  0]\n",
      " [ 1  0  0  0  0  3  0  0 42  0  2  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 62  0  1  0  0  0  0  0]\n",
      " [ 6  0  1  1  1  4  1  0  3  0 43  2  0  1  0  1  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0 49  0  0  0  0  0]\n",
      " [ 1  0  1  0  0  5  0  0  1  3  5  0 49  2  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 55  0  0  0]\n",
      " [ 0  1  2  0  3  1  0  1  0  0  3  0  0  0 50  1  0]\n",
      " [ 0  0  0  0  0  2  2  0  0  0  0  1  1  0  0 58  1]\n",
      " [ 1  0  0  0  0  4  0  0  1  0  0  0  0  3  1  1 54]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost Classifier\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(\"Model:\", name)\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf1ebd",
   "metadata": {},
   "source": [
    "# Model Selection (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "406327da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7861811391223156\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71        68\n",
      "           1       0.82      0.96      0.88        72\n",
      "           2       0.81      0.84      0.83        57\n",
      "           3       0.84      0.91      0.88        58\n",
      "           4       0.73      0.41      0.52        66\n",
      "           5       0.41      0.21      0.28        76\n",
      "           6       0.80      0.93      0.86        71\n",
      "           7       0.94      0.74      0.83        61\n",
      "           8       0.84      0.94      0.88        49\n",
      "           9       0.81      0.95      0.88        63\n",
      "          10       0.64      0.73      0.69        64\n",
      "          11       0.85      1.00      0.92        50\n",
      "          12       0.94      0.72      0.82        69\n",
      "          13       0.68      0.98      0.81        55\n",
      "          14       0.83      0.77      0.80        62\n",
      "          15       0.89      0.88      0.88        65\n",
      "          16       0.79      0.86      0.82        65\n",
      "\n",
      "    accuracy                           0.79      1071\n",
      "   macro avg       0.78      0.80      0.78      1071\n",
      "weighted avg       0.78      0.79      0.77      1071\n",
      "\n",
      "Confusion Matrix:  [[50  1  2  1  2  1  0  0  1  3  2  0  1  2  0  1  1]\n",
      " [ 0 69  0  1  0  0  0  0  0  1  0  0  0  0  0  0  1]\n",
      " [ 2  0 48  0  0  0  2  0  1  0  2  1  0  0  0  1  0]\n",
      " [ 1  3  0 53  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 5  2  3  1 27  6  2  1  2  2  4  3  0  1  3  2  2]\n",
      " [ 6  5  4  1  2 16  3  0  3  3 11  0  1 11  3  1  6]\n",
      " [ 1  0  0  0  0  0 66  0  0  0  3  1  0  0  0  0  0]\n",
      " [ 3  0  0  2  0  3  1 45  1  0  1  0  0  2  1  0  2]\n",
      " [ 2  0  0  0  0  0  0  0 46  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 60  0  1  0  0  0  1  1]\n",
      " [ 2  0  2  2  0  3  3  0  1  1 47  2  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0  0]\n",
      " [ 0  2  0  0  1  5  1  0  0  2  1  0 50  5  1  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 54  1  0  0]\n",
      " [ 0  1  0  1  3  2  2  2  0  0  1  1  1  0 48  0  0]\n",
      " [ 0  1  0  1  2  0  2  0  0  0  0  0  0  1  0 57  1]\n",
      " [ 0  0  0  0  0  3  1  0  0  2  0  0  0  3  0  0 56]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print(\"Report: \",classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2297114b",
   "metadata": {},
   "source": [
    "# Single Input Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ff0f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 12\n",
      "Model Prediction : 12\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "print(\"Actual Label :\", y_test.iloc[10])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0502b39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 0\n",
      "Model Prediction : 0\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 2\n",
    "print(\"Actual Label :\", y_test.iloc[300])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[300].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28bdd4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 3\n",
      "Model Prediction : 3\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 2\n",
    "print(\"Actual Label :\", y_test.iloc[23])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[23].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1cc97f",
   "metadata": {},
   "source": [
    "# Saving & Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c88ef663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Save the scaler and the model\n",
    "with open(\"Models/scaler.pkl\", \"wb\") as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "with open(\"Models/model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0238be1",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eff89839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model supports predict_proba\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the scaler, label encoder, model, and class names\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))\n",
    "\n",
    "# Verify the model type\n",
    "print(\n",
    "    type(model)\n",
    ")  # Should output something like <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
    "\n",
    "# Check if model supports predict_proba\n",
    "if hasattr(model, \"predict_proba\"):\n",
    "    print(\"Model supports predict_proba\")\n",
    "else:\n",
    "    print(\"Model does NOT support predict_proba\")\n",
    "    \n",
    "class_names = [\n",
    "    \"Bachelor of Supply Chain Management\",\n",
    "    \"Bachelor of Statistics\",\n",
    "    \"Bachelor of Corporate Communications\",\n",
    "    \"Bachelor of Human Resouce Management\",\n",
    "    \"Bachelor of Development Studies\",\n",
    "    \"Bachelor of Procurement and Contract Management\",\n",
    "    \"Bachelor of Project Management\",\n",
    "    \"Bachelor of Business Administration\",\n",
    "    \"Bachelor of Journalism\",\n",
    "    \"Bachelor of Business and Office Management\",\n",
    "    \"Bachelor of Economics and Statistics\",\n",
    "    \"Bachelor of Mass Communication\",\n",
    "    \"Bachelor of Commerce\",\n",
    "    \"Bachelor of Procurement and Logistics\",\n",
    "    \"Bachelor of Finance\",\n",
    "    \"Bachelor of Business Information Technology\",\n",
    "    \"Bachelor of Technology and Entrepreneurship Management\",\n",
    "]\n",
    "\n",
    "def Recommendations(gender, extracurricular_activities,\n",
    "                    riasec, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score,\n",
    "                    total_score,average_score):\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "    \n",
    "    # Create feature array\n",
    "    feature_array = np.array([[gender_encoded, extracurricular_activities_encoded,\n",
    "                               riasec, math_score, history_score, physics_score,\n",
    "                               chemistry_score, biology_score, english_score, geography_score,total_score,average_score]])\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "    \n",
    "    # Predict using the model\n",
    "    probabilities = model.predict_proba(scaled_features)\n",
    "    \n",
    "    # Get top five predicted classes along with their probabilities\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:5]\n",
    "    top_classes_names_probs = [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n",
    "    \n",
    "    return top_classes_names_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9d10c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Bachelor of Project Management with probability 0.61\n",
      "Bachelor of Development Studies with probability 0.13\n",
      "Bachelor of Business Administration with probability 0.09\n",
      "Bachelor of Finance with probability 0.04\n",
      "Bachelor of Human Resouce Management with probability 0.03\n"
     ]
    }
   ],
   "source": [
    "# Example usage 1\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        extracurricular_activities=False,\n",
    "                                        riasec=32,\n",
    "                                        math_score=65,\n",
    "                                        history_score=60,\n",
    "                                        physics_score=97,\n",
    "                                        chemistry_score=94,\n",
    "                                        biology_score=71,\n",
    "                                        english_score=81,\n",
    "                                        geography_score=66,\n",
    "                                        total_score=534,\n",
    "                                        average_score=76.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27160dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Bachelor of Human Resouce Management with probability 0.43\n",
      "Bachelor of Business Administration with probability 0.13\n",
      "Bachelor of Supply Chain Management with probability 0.08\n",
      "Bachelor of Finance with probability 0.07\n",
      "Bachelor of Procurement and Contract Management with probability 0.07\n"
     ]
    }
   ],
   "source": [
    "# Example usage 2\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        extracurricular_activities=False,\n",
    "                                        riasec=40,\n",
    "                                        math_score=87,\n",
    "                                        history_score=73,\n",
    "                                        physics_score=67,\n",
    "                                        chemistry_score=91,\n",
    "                                        biology_score=79,\n",
    "                                        english_score=60,\n",
    "                                        geography_score=77,\n",
    "                                        total_score=583,\n",
    "                                        average_score=83.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c9aca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1.post1\n"
     ]
    }
   ],
   "source": [
    "# sklear version in pychar production \n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "# in pycharm env install\n",
    "# pip install scikit-learn==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b058bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
